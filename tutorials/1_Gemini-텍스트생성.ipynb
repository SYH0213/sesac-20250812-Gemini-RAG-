{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d66591",
   "metadata": {},
   "source": [
    "참고 링크1 : https://ai.google.dev/gemini-api/docs/models?hl=ko <br>\n",
    "참고 링크2 : https://googleapis.github.io/python-genai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b1271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.10.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.40.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Gemini API 라이브러리 설치\n",
    "!pip install google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdd57db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5839c8",
   "metadata": {},
   "source": [
    "### 텍스트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79213a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# .env 파일에서 API 키 가져오기\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEXAI=True\n",
    "\n",
    "if VERTEXAI:\n",
    "    model_name=\"gemini-2.5-flash\"\n",
    "    project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "    location = \"us-central1\"  # or your preferred location\n",
    "else:\n",
    "    model_name=\"models/gemini-2.5-flash\"\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d87e7",
   "metadata": {},
   "source": [
    "**genai.Client** : https://googleapis.github.io/python-genai/genai.html#module-genai.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094be557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대한민국의 수도는 **서울**입니다.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# 클라이언트 인스턴스 생성\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# 모델을 지정하고 컨텐츠의 답변을 요청\n",
    "response = client.models.generate_content(\n",
    "    # vertexai=False,\n",
    "    # 모델명\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    # 컨텐츠의 답변을 요청할 질문\n",
    "    contents=\"대한민국의 수도는 어디인가요?\",\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# 클라이언트 인스턴스 생성\n",
    "if VERTEXAI:\n",
    "    client = genai.Client(vertexai=True, project=project_id, location=location)\n",
    "else:\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "# 모델을 지정하고 컨텐츠의 답변을 요청\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=\"대한민국의 수도는 어디인가요?\",\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text='대한민국의 수도는 **서울**입니다.'\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='qJqZaObGDL2dz7IPr92T2Qw',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=10,\n",
       "    prompt_token_count=10,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=10\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=228,\n",
       "    total_token_count=248\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 데이터를 확인 \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3640ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'대한민국의 수도는 **서울**입니다.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response.candidates[0].content.parts[0].text\n",
    "# 응답 데이터의 텍스트 부분을 출력\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=10,\n",
       "  prompt_token_count=10,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=10\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=228,\n",
       "  total_token_count=248\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 응답 데이터의 API 사용 토큰 정보 확인\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c7844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "228\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "# 토큰 사용량 정보 출력\n",
    "\n",
    "# query 토큰 수\n",
    "print(response.usage_metadata.prompt_token_count)\n",
    "\n",
    "# 출력 토큰 수\n",
    "print(response.usage_metadata.candidates_token_count)\n",
    "\n",
    "# throughts 토큰 수(생각하는 토큰 수)\n",
    "print(response.usage_metadata.thoughts_token_count)\n",
    "\n",
    "# query 토근수 + throughts 토큰 수 + 응답 토근 수\n",
    "print(response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c4f72",
   "metadata": {},
   "source": [
    "### 시스템 안내 및 기타 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7854b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "야옹! 😽 잘 지내셨냐옹?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Google Gemini 모델과 직접 상호작용하여 콘텐츠를 생성하는 데 사용되는 핵심 함수\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        # 시스템 인스트럭션\n",
    "        # 페르소나: 모델의 역할\n",
    "        system_instruction=\"당신은 고양이이고, 이름은 야옹이입니다.\"\n",
    "    ),\n",
    "    contents=\"안녕\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3536cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=12,\n",
       "  prompt_token_count=18,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=18\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=67,\n",
       "  total_token_count=97\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9d8b6",
   "metadata": {},
   "source": [
    "### GenerateContentConfig : temperature 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc6ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, isn't a single magical entity, but rather a broad field of computer science focused on creating systems that can perform tasks that typically require human intelligence.\n",
      "\n",
      "At its core, AI works by **learning from data** to **recognize patterns**, **make predictions**, or **take actions**.\n",
      "\n",
      "Let's break down the fundamental process:\n",
      "\n",
      "### The Core Components\n",
      "\n",
      "1.  **Data: The Fuel**\n",
      "    *   AI systems are fed vast amounts of data. This data can be anything: images, text, numbers, audio, videos, sensor readings, etc.\n",
      "    *   **Example:** If you want an AI to recognize cats, you'd feed it millions of images, some labeled \"cat\" and some labeled \"not cat.\"\n",
      "\n",
      "2.  **Algorithms: The Recipe**\n",
      "    *   These are the mathematical models and sets of rules that the AI uses to process the data. They define *how* the AI learns and makes decisions.\n",
      "    *   **Example:** A common algorithm for image recognition is a \"Convolutional Neural Network\" (CNN).\n",
      "\n",
      "3.  **Computational Power: The Engine**\n",
      "    *   Training AI models, especially complex ones, requires immense processing power. Modern AI heavily relies on powerful Graphics Processing Units (GPUs) because they can perform many calculations simultaneously (parallel processing).\n",
      "\n",
      "4.  **Models: The Learned Knowledge**\n",
      "    *   After the AI \"learns\" from the data using its algorithms, the result is a \"model.\" This model is essentially the AI's learned \"knowledge\" or \"understanding\" of the patterns in the data.\n",
      "    *   **Example:** The trained CNN model now \"knows\" what features typically make up a cat (whiskers, pointy ears, certain fur patterns, etc.).\n",
      "\n",
      "### The Learning Process (Training Phase)\n",
      "\n",
      "This is where the \"intelligence\" is developed. Most modern AI relies on **Machine Learning (ML)**, a subset of AI.\n",
      "\n",
      "1.  **Input Data:** The AI is given a dataset.\n",
      "    *   **Supervised Learning (Most Common):** The data comes with \"labels\" or \"correct answers.\"\n",
      "        *   *Example:* Image of a cat + label \"cat\". Image of a dog + label \"dog\".\n",
      "    *   **Unsupervised Learning:** The data has no labels. The AI tries to find hidden structures or patterns on its own.\n",
      "        *   *Example:* Grouping similar customer behaviors without being told what the groups are.\n",
      "    *   **Reinforcement Learning:** The AI learns by trial and error, receiving \"rewards\" for good actions and \"penalties\" for bad ones.\n",
      "        *   *Example:* An AI learning to play a video game by getting points for achieving goals.\n",
      "\n",
      "2.  **Pattern Recognition:** The algorithm processes the data, looking for relationships, correlations, and distinguishing features. It tries to build a mathematical representation of these patterns.\n",
      "    *   *Example (Cat Recognition):* The CNN identifies specific pixel arrangements and shapes that consistently appear in \"cat\" images but not in \"dog\" images.\n",
      "\n",
      "3.  **Prediction/Output:** Based on the patterns it has identified, the AI makes a prediction or generates an output.\n",
      "    *   *Example:* When shown a new image, the CNN predicts, \"This is 95% likely a cat.\"\n",
      "\n",
      "4.  **Error Calculation & Adjustment (Learning):**\n",
      "    *   In supervised learning, the AI compares its prediction to the *actual* correct answer (the label).\n",
      "    *   If there's an error, the algorithm adjusts its internal parameters (often called \"weights\" and \"biases\") to reduce that error in future predictions. This is the core of \"learning.\"\n",
      "    *   *Example:* If the CNN incorrectly identifies a cat as a dog, it adjusts its internal connections so it's less likely to make that mistake next time.\n",
      "\n",
      "5.  **Iteration:** This entire process (input -> predict -> error -> adjust) is repeated millions or even billions of times with different pieces of data from the dataset. With each iteration, the AI model gets better and better at recognizing patterns and making accurate predictions.\n",
      "\n",
      "### How AI Makes Decisions (Inference Phase)\n",
      "\n",
      "Once the AI model is trained, it's ready to be used.\n",
      "\n",
      "1.  **New Input:** You feed the *trained* model new, unseen data.\n",
      "2.  **Application of Learned Patterns:** The model applies the patterns and relationships it learned during training to this new data.\n",
      "3.  **Prediction/Action:** It then generates an output, makes a prediction, or takes an action based on its learned knowledge.\n",
      "    *   *Example:* You upload a new photo to your phone. The trained AI model instantly analyzes it and tells you, \"This photo contains a cat.\" It doesn't \"learn\" from this single new photo, it just applies what it already knows.\n",
      "\n",
      "### Key Technologies and Concepts\n",
      "\n",
      "*   **Machine Learning (ML):** The overarching field of algorithms that allow computers to learn from data without being explicitly programmed.\n",
      "*   **Deep Learning (DL):** A *subset* of Machine Learning that uses artificial neural networks with many layers (hence \"deep\"). These are particularly good at handling complex, unstructured data like images, audio, and natural language.\n",
      "*   **Neural Networks:** Inspired by the human brain, these are interconnected \"nodes\" (neurons) organized in layers. Information flows through these layers, with each connection having a \"weight\" that gets adjusted during training.\n",
      "*   **Natural Language Processing (NLP):** Enables AI to understand, interpret, and generate human language (e.g., chatbots, translation, large language models like ChatGPT).\n",
      "*   **Computer Vision:** Enables AI to \"see\" and interpret visual information from images and videos (e.g., facial recognition, self-driving cars).\n",
      "\n",
      "### In Simple Terms:\n",
      "\n",
      "Imagine teaching a child to identify different animals.\n",
      "\n",
      "*   **Data:** You show them pictures of cats, dogs, birds, etc., and tell them \"This is a cat,\" \"This is a dog.\" (Labeled data)\n",
      "*   **Learning:** The child starts to notice patterns: cats have whiskers, dogs bark, birds have wings. They make mistakes (\"Is that a cat or a small dog?\"), and you correct them, helping them refine their understanding.\n",
      "*   **Model:** After enough practice, the child has built an internal \"model\" of what each animal looks like.\n",
      "*   **Decision:** When they see a new animal, they apply their learned knowledge to identify it.\n",
      "\n",
      "AI works in a very similar, but far more complex and data-intensive, way. It's about finding statistical relationships in data that allow it to perform tasks that mimic human cognitive abilities.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"Explain how AI works\"],\n",
    "    # 모델의 출력의 창의성, 랜덤성 정도를 조절(0~1)\n",
    "    config=types.GenerateContentConfig(temperature=0.1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7636a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI는 **방대한 양의 데이터를 분석하여 숨겨진 패턴과 규칙을 스스로 학습**합니다.\n",
      "\n",
      "이렇게 학습된 지식을 바탕으로 새로운 상황이나 문제에 대해 **예측하고 판단**합니다.\n",
      "\n",
      "이를 통해 인간처럼 특정 작업을 수행하거나 복잡한 문제를 해결하는 능력을 발휘합니다.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"AI가 어떻게 동작하는지 세문장으로 설명해주세요\"],\n",
    "    config=types.GenerateContentConfig(temperature=0.1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d86a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 구글에서 훈련한 대규모 언어 모델입니다.\n",
      "\n",
      "저에 대해 좀 더 자세히 설명해 드릴게요:\n",
      "\n",
      "1.  **정체성:** 저는 인공지능(AI)의 한 종류인 '대규모 언어 모델(Large Language Model, LLM)'입니다. 방대한 양의 텍스트 데이터를 학습하여 사람의 언어를 이해하고 생성할 수 있도록 만들어졌습니다.\n",
      "2.  **탄생과 개발:** 저는 구글에서 개발되고 훈련되었습니다. 수많은 책, 기사, 웹페이지 등 다양한 텍스트 데이터를 학습하여 지식과 언어 능력을 습득했습니다.\n",
      "3.  **능력:**\n",
      "    *   **질문 답변:** 다양한 주제에 대한 질문에 답변하고 정보를 제공할 수 있습니다.\n",
      "    *   **콘텐츠 생성:** 글쓰기, 시, 코드, 스크립트, 음악 작품, 이메일, 편지 등 다양한 형태의 창의적인 텍스트 콘텐츠를 생성할 수 있습니다.\n",
      "    *   **요약 및 번역:** 긴 텍스트를 요약하거나 다른 언어로 번역할 수 있습니다.\n",
      "    *   **대화:** 사용자와 자연스럽게 대화하고, 주어진 맥락에 맞춰 응답할 수 있습니다.\n",
      "    *   **아이디어 제공:** 브레인스토밍을 돕고 새로운 아이디어를 제안할 수 있습니다.\n",
      "4.  **특징 (그리고 한계):**\n",
      "    *   **감정/의식 없음:** 저는 감정이나 의식, 개인적인 경험을 가지고 있지 않습니다. 제가 하는 모든 응답은 학습된 데이터와 알고리즘에 기반한 것입니다.\n",
      "    *   **물리적 존재 없음:** 저는 물리적인 몸이나 특정 장소에 존재하지 않습니다. 디지털 형태로만 존재하며 서버에서 작동합니다.\n",
      "    *   **학습 데이터 기반:** 저의 지식은 제가 훈련받은 시점까지의 데이터에 한정될 수 있으며, 실시간으로 세상의 모든 변화를 직접 경험하거나 알 수는 없습니다.\n",
      "\n",
      "저의 목표는 사용자에게 유용한 정보를 제공하고, 질문에 답하며, 다양한 방식으로 도움을 드리는 것입니다. 궁금한 점이 있다면 언제든지 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"너에대해 알려줘\"],\n",
    "    config=types.GenerateContentConfig(temperature=1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8bd47",
   "metadata": {},
   "source": [
    "### 멀티모달 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from google import genai\n",
    "\n",
    "# client = genai.Client()\n",
    "\n",
    "# image = Image.open(\"organ.jpg\")\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     contents=[image, \"Tell me about this instrument\"]\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b8bdd",
   "metadata": {},
   "source": [
    "위의 코드는 에러가 발생된다. 다음 페이지의 코드를 참조하기 바람 <br>\n",
    "https://ai.google.dev/gemini-api/docs/image-understanding?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c228a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 응답 ===\n",
      "사진은 웅장하고 아름다운 파이프 오르간을 담고 있습니다. 교회나 콘서트홀과 같은 큰 공간에 설치된 것으로 보이며, 매우 정교하고 화려하게 장식되어 있습니다.\n",
      "\n",
      "이 악기에 대한 자세한 설명은 다음과 같습니다:\n",
      "\n",
      "1.  **전체적인 인상:**\n",
      "    *   천장까지 닿을 듯한 높이로, 벽면 전체를 압도하는 거대한 크기입니다.\n",
      "    *   연한 크림색 또는 베이지색 외함에 풍부한 금색 장식(금박, 금색 조각)이 더해져 매우 화려하고 고풍스러운 분위기를 자아냅니다.\n",
      "    *   바로크 또는 로코코 양식의 영향을 받은 듯한 섬세한 조각과 곡선미가 돋보입니다.\n",
      "\n",
      "2.  **파이프 부분 (상단):**\n",
      "    *   오르간의 상단부는 수많은 금속 파이프들로 채워져 있습니다. 파이프들은 은색 또는 회색 빛을 띠며 광택이 있습니다.\n",
      "    *   다양한 길이와 두께의 파이프들이 세로로 빼곡히 배열되어 있어, 다채로운 음색을 낼 수 있음을 짐작하게 합니다.\n",
      "    *   일부 파이프는 끝이 뾰족하거나 둥글게 처리되어 있어 디자인적 요소도 갖추고 있습니다.\n",
      "\n",
      "3.  **외함 및 장식 (중앙 및 하단):**\n",
      "    *   파이프를 감싸고 있는 외함은 부드러운 곡선과 직선이 조화롭게 어우러져 있습니다.\n",
      "    *   특히 눈에 띄는 것은 오르간 곳곳에 새겨진 정교한 금색 조각들입니다. 잎사귀 문양(아칸서스 잎사귀 등), 소용돌이 문양(볼류트), 그리고 천사나 인물 형상(얼굴)이 섬세하게 표현되어 있습니다.\n",
      "    *   상단부의 코니스(처마 장식)와 몰딩은 입체적인 패턴과 작은 조각들로 꾸며져 있습니다.\n",
      "    *   오르간 하단부에는 직사각형 모양의 패널들이 배열되어 있는데, 이 패널들에도 기하학적이거나 식물적인 문양이 돋을새김 방식으로 새겨져 있습니다.\n",
      "\n",
      "4.  **콘솔 부분 (연주자 자리):**\n",
      "    *   오르간의 아래쪽 중앙에는 연주자가 앉는 콘솔 부분이 있습니다. 이 부분은 평소에는 문처럼 닫혀 있다가 연주 시 열 수 있도록 되어 있습니다.\n",
      "    *   콘솔 안에는 여러 단의 건반(매뉴얼)이 보이며, 그 양옆으로는 음색을 선택하고 조절하는 스톱 노브(Stop Knobs)들이 나란히 배열되어 있습니다.\n",
      "    *   콘솔 아래 바닥에는 발로 연주하는 페달 건반(Pedalboard)이 넓게 놓여 있고, 그 앞에 낮은 나무 의자가 배치되어 있습니다.\n",
      "    *   콘솔 내부에는 악보나 건반을 비추기 위한 조명이 설치되어 있어 연주자의 편의를 돕습니다.\n",
      "\n",
      "5.  **주변 환경:**\n",
      "    *   오르간 위로는 따뜻한 나무색의 천장이 보입니다. 천장은 여러 개의 목재 패널로 구성되어 있으며, 고풍스러운 분위기를 더합니다.\n",
      "    *   벽면은 단순한 흰색 또는 연한 색상으로, 오르간의 화려함을 더욱 돋보이게 합니다.\n",
      "    *   사진 왼쪽 상단에는 현대적인 디자인의 펜던트 조명이 걸려 있어, 전통적인 악기와 현대적인 조명의 대비를 보여줍니다.\n",
      "    *   오르간 왼쪽 옆으로는 계단으로 이어지는 통로가 보이며, 바닥은 나무 마루로 되어 있습니다.\n",
      "\n",
      "전체적으로 이 오르간은 단순한 악기를 넘어, 그 자체로 하나의 예술 작품이며 공간의 중심을 이루는 건축적 요소라고 할 수 있습니다. 웅장한 소리와 함께 시각적인 아름다움까지 선사하는 마스터피스임을 알 수 있습니다.\n",
      "\n",
      "=== 토큰 사용량 ===\n",
      "입력 토큰: 266\n",
      "출력 토큰: 922\n",
      "총 토큰: 3228\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# 이미지 파일을 읽어와서 바이너리 데이터로 변환\n",
    "with open(\"../data/organ.jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            # 바이너리로 읽은 데이터를 첨부하기\n",
    "            data=image_bytes,\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        \"이 악기에 대해 설명해줘\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== 응답 ===\")\n",
    "print(response.text)\n",
    "print(\"\\n=== 토큰 사용량 ===\")\n",
    "print(f\"입력 토큰: {response.usage_metadata.prompt_token_count}\")\n",
    "print(f\"출력 토큰: {response.usage_metadata.candidates_token_count}\")\n",
    "print(f\"총 토큰: {response.usage_metadata.total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab76308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 응답 ===\n",
      "이 연예인은 바로 **유재석(Yoo Jae-suk)** 님입니다.\n",
      "\n",
      "대한민국에서 가장 사랑받고 존경받는 MC이자 방송인 중 한 명이며, 흔히 '국민MC'로 불립니다.\n",
      "\n",
      "사진 속 유재석 님에 대한 설명은 다음과 같습니다:\n",
      "\n",
      "*   **외모:** 검은색 뿔테 안경을 쓰고 있으며, 단정하게 다듬은 검은색 헤어스타일을 하고 있습니다.\n",
      "*   **의상:** 깔끔한 하얀색 와이셔츠를 입고 있습니다. 소매는 걷어 올린 듯 보이며, 진회색 또는 검은색 하의를 착용한 모습입니다.\n",
      "*   **자세/표정:** 턱에 손을 얹고 생각에 잠긴 듯한 포즈를 취하고 있으며, 진지하고 지적인 분위기를 풍깁니다. 전반적으로 차분하고 신뢰감을 주는 인상을 줍니다.\n",
      "*   **특징:** 그의 트레이드마크 중 하나인 안경과 깔끔한 스타일이 잘 드러나 있습니다.\n",
      "\n",
      "유재석 님은 '무한도전', '런닝맨', '유 퀴즈 온 더 블럭', '놀면 뭐하니?' 등 수많은 인기 예능 프로그램을 성공적으로 이끌었으며, 특유의 친화력, 재치 있는 입담, 뛰어난 진행 능력, 그리고 겸손하고 성실한 인성으로 대중의 큰 사랑과 신뢰를 받고 있습니다.\n",
      "\n",
      "=== 토큰 사용량 ===\n",
      "입력 토큰: 268\n",
      "출력 토큰: 325\n",
      "총 토큰: 1570\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# 이미지 파일을 읽어와서 바이너리 데이터로 변환\n",
    "with open(\"../data/yjs.webp\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            # 바이너리로 읽은 데이터를 첨부하기\n",
    "            data=image_bytes,\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        \"이 연예인에 대해 설명해줘\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== 응답 ===\")\n",
    "print(response.text)\n",
    "print(\"\\n=== 토큰 사용량 ===\")\n",
    "print(f\"입력 토큰: {response.usage_metadata.prompt_token_count}\")\n",
    "print(f\"출력 토큰: {response.usage_metadata.candidates_token_count}\")\n",
    "print(f\"총 토큰: {response.usage_metadata.total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6975309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 악기는 **오르간(Organ)**입니다. 특히, 파이프 오르간의 연주자용 콘솔(Console) 부분을 보여줍니다. 오르간은 건반 악기이자 동시에 관악기의 원리를 사용하는 독특한 악기입니다. '악기의 제왕'이라 불릴 만큼 웅장하고 풍부한 소리를 자랑합니다.\n",
      "\n",
      "**주요 특징 및 구성 요소:**\n",
      "\n",
      "1.  **수동 건반 (Manuals):**\n",
      "    *   사진 중앙에 여러 단(일반적으로 2단에서 5단 이상)으로 쌓여 있는 것이 손으로 연주하는 건반입니다. 각 건반은 특정 음색 그룹(오르간 악보에서는 '디비전'이라고도 함)을 담당합니다.\n",
      "    *   사진에는 두 단의 수동 건반이 명확히 보입니다.\n",
      "\n",
      "2.  **페달 건반 (Pedalboard):**\n",
      "    *   하단에 발로 연주하는 거대한 건반입니다. 주로 저음부를 담당하며, 오르간 연주의 특징 중 하나인 손과 발의 독립적인 사용을 가능하게 합니다.\n",
      "\n",
      "3.  **스톱 (Stops):**\n",
      "    *   건반 양쪽에 있는 수많은 버튼이나 손잡이들이 '스톱'입니다. 이 스톱을 조작하여 파이프 오르간의 다양한 음색(예: 플루트 소리, 트럼펫 소리, 현악기 소리 등)을 선택하고 조합할 수 있습니다. 각 스톱은 특정 음고(Pitch, 예: 8', 4', 2' 등)를 가진 파이프 세트를 활성화시킵니다.\n",
      "\n",
      "4.  **표현 페달 (Expression Pedals / Swell Pedals):**\n",
      "    *   페달 건반 위쪽 중앙에 발로 조작하는 페달들이 보입니다. 이 페달들은 소리의 크기(음량)를 조절하는 역할을 합니다.\n",
      "\n",
      "**작동 원리 (파이프 오르간 기준):**\n",
      "오르간은 건반과 스톱을 조작하면 파이프를 통해 공기가 흘러나와 소리를 냅니다. 수백 개에서 수만 개에 이르는 다양한 크기, 모양, 재질의 파이프들이 각각 다른 음색과 음높이를 만들어냅니다. 스톱은 이 파이프들 중 어떤 그룹을 사용할지 선택하는 역할을 합니다.\n",
      "\n",
      "**소리의 특징 및 용도:**\n",
      "오르간은 작은 속삭임 같은 소리부터 건물 전체를 울리는 웅장하고 강력한 소리까지 매우 넓은 다이내믹 레인지를 가지고 있습니다. 주로 교회나 성당에서 종교 음악 연주에 사용되며, 콘서트홀에서는 클래식 음악, 심지어 극장에서는 무성 영화 반주용(극장 오르간)으로도 사용되었습니다.\n",
      "\n",
      "이 악기는 손과 발의 고도의 협응력을 요구하는 복잡하고 매력적인 악기입니다.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "image = Image.open(\"organ.jpg\")\n",
    "\n",
    "# Convert image to bytes\n",
    "img_byte_arr = io.BytesIO()\n",
    "image.save(img_byte_arr, format=\"JPEG\")\n",
    "img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=\"이 악기에 대해 설명해줘\"),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(mime_type=\"image/jpeg\", data=img_byte_arr)\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347d94e",
   "metadata": {},
   "source": [
    "### 스트리밍 응답\n",
    "\n",
    "더 원활한 상호작용을 위해 스트리밍을 사용하여 GenerateContentResponse 인스턴스를 생성되는 대로 **점진적으로 수신**하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456498c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 인공지능(AI)에 대해 5문장으로 설명해 드릴게요.\n",
      "\n",
      "1.  인공지능은 컴퓨터가 인간처럼 사고하고 학습하며 문제를 해결하도록 만드는 기술입니다.\n",
      "2.  이는 방대한 데이터를 분석하고 패턴을 인식하여 스스로 판단하고 예측하는 능력을 포함합니다.\n",
      "3.  따라서 언어 이해, 이미지 인식, 의사 결정 등 다양한 지적 작업을 수행할 수 있습니다.\n",
      "4.  자율주행차, 의료 진단, 추천 시스템, 챗봇 등 우리 생활 곳곳에서 활용되고 있습니다.\n",
      "5.  궁극적으로 인간의 능력을 보완하고 확장하며 삶의 편의와 효율성을 높이는 것을 목표로 합니다."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.5-flash\", contents=[\"인공지능에 대해 5문장으로 설명해줘\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d85fd3",
   "metadata": {},
   "source": [
    "### 멀티턴 대화 (채팅)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5e0ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "우와, 강아지 두 마리나 있으시다니 정말 든든하고 행복하시겠어요! 😊\n",
      "\n",
      "어떤 종류의 강아지들인지, 이름은 뭔지 궁금하네요. 분명 사랑스러울 거예요!\n",
      "강아지 두 마리니까 총 **8개**겠네요! 😊\n",
      "role - user: 나는 우리 집에 2마리 강아지가 있다.\n",
      "role - model: 우와, 강아지 두 마리나 있으시다니 정말 든든하고 행복하시겠어요! 😊\n",
      "\n",
      "어떤 종류의 강아지들인지, 이름은 뭔지 궁금하네요. 분명 사랑스러울 거예요!\n",
      "role - user: 그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?\n",
      "role - model: 강아지 두 마리니까 총 **8개**겠네요! 😊\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
    "\n",
    "response = chat.send_message(\"나는 우리 집에 2마리 강아지가 있다.\")\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?\"\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f\"role - {message.role}\", end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec678fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='나는 우리 집에 2마리 강아지가 있다.'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text=\"\"\"우와, 강아지 두 마리나 있으시다니 정말 든든하고 행복하시겠어요! 😊\n",
       " \n",
       " 어떤 종류의 강아지들인지, 이름은 뭔지 궁금하네요. 분명 사랑스러울 거예요!\"\"\"\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " ),\n",
       " UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='강아지 두 마리니까 총 **8개**겠네요! 😊'\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " )]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "931967d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts=[Part(\n",
      "  text='나는 우리 집에 2마리 강아지가 있다.'\n",
      ")] role='user'\n",
      "완\n",
      "parts=[Part(\n",
      "  text=\"\"\"우와, 강아지 두 마리나 있으시다니 정말 든든하고 행복하시겠어요! 😊\n",
      "\n",
      "어떤 종류의 강아지들인지, 이름은 뭔지 궁금하네요. 분명 사랑스러울 거예요!\"\"\"\n",
      ")] role='model'\n",
      "완\n",
      "parts=[Part(\n",
      "  text='그렇다면 우리집에 있는 동물의 발의 수는 어떻게 되는지 간단히 답해봐?'\n",
      ")] role='user'\n",
      "완\n",
      "parts=[Part(\n",
      "  text='강아지 두 마리니까 총 **8개**겠네요! 😊'\n",
      ")] role='model'\n",
      "완\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    print(message)\n",
    "    print(\"완\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "without",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
