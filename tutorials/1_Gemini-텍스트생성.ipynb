{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9d66591",
   "metadata": {},
   "source": [
    "ì°¸ê³  ë§í¬1 : https://ai.google.dev/gemini-api/docs/models?hl=ko <br>\n",
    "ì°¸ê³  ë§í¬2 : https://googleapis.github.io/python-genai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b1271f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.29.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.10.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.40.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (2.32.4)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-genai) (4.14.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sba\\miniconda3\\envs\\without\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Gemini API ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bdd57db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env íŒŒì¼ ë¡œë“œ\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5839c8",
   "metadata": {},
   "source": [
    "### í…ìŠ¤íŠ¸ ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79213a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# .env íŒŒì¼ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERTEXAI=True\n",
    "\n",
    "if VERTEXAI:\n",
    "    model_name=\"gemini-2.5-flash\"\n",
    "    project_id = os.getenv(\"GOOGLE_CLOUD_PROJECT_ID\")\n",
    "    location = \"us-central1\"  # or your preferred location\n",
    "else:\n",
    "    model_name=\"models/gemini-2.5-flash\"\n",
    "    api_key = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796d87e7",
   "metadata": {},
   "source": [
    "**genai.Client** : https://googleapis.github.io/python-genai/genai.html#module-genai.client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094be557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# ëª¨ë¸ì„ ì§€ì •í•˜ê³  ì»¨í…ì¸ ì˜ ë‹µë³€ì„ ìš”ì²­\n",
    "response = client.models.generate_content(\n",
    "    # vertexai=False,\n",
    "    # ëª¨ë¸ëª…\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    # ì»¨í…ì¸ ì˜ ë‹µë³€ì„ ìš”ì²­í•  ì§ˆë¬¸\n",
    "    contents=\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e3b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "# import google.generativeai as genai\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "if VERTEXAI:\n",
    "    client = genai.Client(vertexai=True, project=project_id, location=location)\n",
    "else:\n",
    "    client = genai.Client(api_key=api_key)\n",
    "\n",
    "# ëª¨ë¸ì„ ì§€ì •í•˜ê³  ì»¨í…ì¸ ì˜ ë‹µë³€ì„ ìš”ì²­\n",
    "response = client.models.generate_content(\n",
    "    model=model_name,\n",
    "    contents=\"ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” ì–´ë””ì¸ê°€ìš”?\",\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daca7651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponse(\n",
       "  automatic_function_calling_history=[],\n",
       "  candidates=[\n",
       "    Candidate(\n",
       "      content=Content(\n",
       "        parts=[\n",
       "          Part(\n",
       "            text='ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤.'\n",
       "          ),\n",
       "        ],\n",
       "        role='model'\n",
       "      ),\n",
       "      finish_reason=<FinishReason.STOP: 'STOP'>,\n",
       "      index=0\n",
       "    ),\n",
       "  ],\n",
       "  model_version='gemini-2.5-flash',\n",
       "  response_id='qJqZaObGDL2dz7IPr92T2Qw',\n",
       "  sdk_http_response=HttpResponse(\n",
       "    headers=<dict len=11>\n",
       "  ),\n",
       "  usage_metadata=GenerateContentResponseUsageMetadata(\n",
       "    candidates_token_count=10,\n",
       "    prompt_token_count=10,\n",
       "    prompt_tokens_details=[\n",
       "      ModalityTokenCount(\n",
       "        modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "        token_count=10\n",
       "      ),\n",
       "    ],\n",
       "    thoughts_token_count=228,\n",
       "    total_token_count=248\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‘ë‹µ ë°ì´í„°ë¥¼ í™•ì¸ \n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3640ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ëŒ€í•œë¯¼êµ­ì˜ ìˆ˜ë„ëŠ” **ì„œìš¸**ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#response.candidates[0].content.parts[0].text\n",
    "# ì‘ë‹µ ë°ì´í„°ì˜ í…ìŠ¤íŠ¸ ë¶€ë¶„ì„ ì¶œë ¥\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=10,\n",
       "  prompt_token_count=10,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=10\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=228,\n",
       "  total_token_count=248\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ì‘ë‹µ ë°ì´í„°ì˜ API ì‚¬ìš© í† í° ì •ë³´ í™•ì¸\n",
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c7844b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "228\n",
      "248\n"
     ]
    }
   ],
   "source": [
    "# í† í° ì‚¬ìš©ëŸ‰ ì •ë³´ ì¶œë ¥\n",
    "\n",
    "# query í† í° ìˆ˜\n",
    "print(response.usage_metadata.prompt_token_count)\n",
    "\n",
    "# ì¶œë ¥ í† í° ìˆ˜\n",
    "print(response.usage_metadata.candidates_token_count)\n",
    "\n",
    "# throughts í† í° ìˆ˜(ìƒê°í•˜ëŠ” í† í° ìˆ˜)\n",
    "print(response.usage_metadata.thoughts_token_count)\n",
    "\n",
    "# query í† ê·¼ìˆ˜ + throughts í† í° ìˆ˜ + ì‘ë‹µ í† ê·¼ ìˆ˜\n",
    "print(response.usage_metadata.total_token_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943c4f72",
   "metadata": {},
   "source": [
    "### ì‹œìŠ¤í…œ ì•ˆë‚´ ë° ê¸°íƒ€ êµ¬ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7854b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•¼ì˜¹! ğŸ˜½ ì˜ ì§€ë‚´ì…¨ëƒì˜¹?\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "# Google Gemini ëª¨ë¸ê³¼ ì§ì ‘ ìƒí˜¸ì‘ìš©í•˜ì—¬ ì½˜í…ì¸ ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” í•µì‹¬ í•¨ìˆ˜\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        # ì‹œìŠ¤í…œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜\n",
    "        # í˜ë¥´ì†Œë‚˜: ëª¨ë¸ì˜ ì—­í• \n",
    "        system_instruction=\"ë‹¹ì‹ ì€ ê³ ì–‘ì´ì´ê³ , ì´ë¦„ì€ ì•¼ì˜¹ì´ì…ë‹ˆë‹¤.\"\n",
    "    ),\n",
    "    contents=\"ì•ˆë…•\",\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3536cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GenerateContentResponseUsageMetadata(\n",
       "  candidates_token_count=12,\n",
       "  prompt_token_count=18,\n",
       "  prompt_tokens_details=[\n",
       "    ModalityTokenCount(\n",
       "      modality=<MediaModality.TEXT: 'TEXT'>,\n",
       "      token_count=18\n",
       "    ),\n",
       "  ],\n",
       "  thoughts_token_count=67,\n",
       "  total_token_count=97\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d9d8b6",
   "metadata": {},
   "source": [
    "### GenerateContentConfig : temperature ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fc6ddec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI, or Artificial Intelligence, isn't a single magical entity, but rather a broad field of computer science focused on creating systems that can perform tasks that typically require human intelligence.\n",
      "\n",
      "At its core, AI works by **learning from data** to **recognize patterns**, **make predictions**, or **take actions**.\n",
      "\n",
      "Let's break down the fundamental process:\n",
      "\n",
      "### The Core Components\n",
      "\n",
      "1.  **Data: The Fuel**\n",
      "    *   AI systems are fed vast amounts of data. This data can be anything: images, text, numbers, audio, videos, sensor readings, etc.\n",
      "    *   **Example:** If you want an AI to recognize cats, you'd feed it millions of images, some labeled \"cat\" and some labeled \"not cat.\"\n",
      "\n",
      "2.  **Algorithms: The Recipe**\n",
      "    *   These are the mathematical models and sets of rules that the AI uses to process the data. They define *how* the AI learns and makes decisions.\n",
      "    *   **Example:** A common algorithm for image recognition is a \"Convolutional Neural Network\" (CNN).\n",
      "\n",
      "3.  **Computational Power: The Engine**\n",
      "    *   Training AI models, especially complex ones, requires immense processing power. Modern AI heavily relies on powerful Graphics Processing Units (GPUs) because they can perform many calculations simultaneously (parallel processing).\n",
      "\n",
      "4.  **Models: The Learned Knowledge**\n",
      "    *   After the AI \"learns\" from the data using its algorithms, the result is a \"model.\" This model is essentially the AI's learned \"knowledge\" or \"understanding\" of the patterns in the data.\n",
      "    *   **Example:** The trained CNN model now \"knows\" what features typically make up a cat (whiskers, pointy ears, certain fur patterns, etc.).\n",
      "\n",
      "### The Learning Process (Training Phase)\n",
      "\n",
      "This is where the \"intelligence\" is developed. Most modern AI relies on **Machine Learning (ML)**, a subset of AI.\n",
      "\n",
      "1.  **Input Data:** The AI is given a dataset.\n",
      "    *   **Supervised Learning (Most Common):** The data comes with \"labels\" or \"correct answers.\"\n",
      "        *   *Example:* Image of a cat + label \"cat\". Image of a dog + label \"dog\".\n",
      "    *   **Unsupervised Learning:** The data has no labels. The AI tries to find hidden structures or patterns on its own.\n",
      "        *   *Example:* Grouping similar customer behaviors without being told what the groups are.\n",
      "    *   **Reinforcement Learning:** The AI learns by trial and error, receiving \"rewards\" for good actions and \"penalties\" for bad ones.\n",
      "        *   *Example:* An AI learning to play a video game by getting points for achieving goals.\n",
      "\n",
      "2.  **Pattern Recognition:** The algorithm processes the data, looking for relationships, correlations, and distinguishing features. It tries to build a mathematical representation of these patterns.\n",
      "    *   *Example (Cat Recognition):* The CNN identifies specific pixel arrangements and shapes that consistently appear in \"cat\" images but not in \"dog\" images.\n",
      "\n",
      "3.  **Prediction/Output:** Based on the patterns it has identified, the AI makes a prediction or generates an output.\n",
      "    *   *Example:* When shown a new image, the CNN predicts, \"This is 95% likely a cat.\"\n",
      "\n",
      "4.  **Error Calculation & Adjustment (Learning):**\n",
      "    *   In supervised learning, the AI compares its prediction to the *actual* correct answer (the label).\n",
      "    *   If there's an error, the algorithm adjusts its internal parameters (often called \"weights\" and \"biases\") to reduce that error in future predictions. This is the core of \"learning.\"\n",
      "    *   *Example:* If the CNN incorrectly identifies a cat as a dog, it adjusts its internal connections so it's less likely to make that mistake next time.\n",
      "\n",
      "5.  **Iteration:** This entire process (input -> predict -> error -> adjust) is repeated millions or even billions of times with different pieces of data from the dataset. With each iteration, the AI model gets better and better at recognizing patterns and making accurate predictions.\n",
      "\n",
      "### How AI Makes Decisions (Inference Phase)\n",
      "\n",
      "Once the AI model is trained, it's ready to be used.\n",
      "\n",
      "1.  **New Input:** You feed the *trained* model new, unseen data.\n",
      "2.  **Application of Learned Patterns:** The model applies the patterns and relationships it learned during training to this new data.\n",
      "3.  **Prediction/Action:** It then generates an output, makes a prediction, or takes an action based on its learned knowledge.\n",
      "    *   *Example:* You upload a new photo to your phone. The trained AI model instantly analyzes it and tells you, \"This photo contains a cat.\" It doesn't \"learn\" from this single new photo, it just applies what it already knows.\n",
      "\n",
      "### Key Technologies and Concepts\n",
      "\n",
      "*   **Machine Learning (ML):** The overarching field of algorithms that allow computers to learn from data without being explicitly programmed.\n",
      "*   **Deep Learning (DL):** A *subset* of Machine Learning that uses artificial neural networks with many layers (hence \"deep\"). These are particularly good at handling complex, unstructured data like images, audio, and natural language.\n",
      "*   **Neural Networks:** Inspired by the human brain, these are interconnected \"nodes\" (neurons) organized in layers. Information flows through these layers, with each connection having a \"weight\" that gets adjusted during training.\n",
      "*   **Natural Language Processing (NLP):** Enables AI to understand, interpret, and generate human language (e.g., chatbots, translation, large language models like ChatGPT).\n",
      "*   **Computer Vision:** Enables AI to \"see\" and interpret visual information from images and videos (e.g., facial recognition, self-driving cars).\n",
      "\n",
      "### In Simple Terms:\n",
      "\n",
      "Imagine teaching a child to identify different animals.\n",
      "\n",
      "*   **Data:** You show them pictures of cats, dogs, birds, etc., and tell them \"This is a cat,\" \"This is a dog.\" (Labeled data)\n",
      "*   **Learning:** The child starts to notice patterns: cats have whiskers, dogs bark, birds have wings. They make mistakes (\"Is that a cat or a small dog?\"), and you correct them, helping them refine their understanding.\n",
      "*   **Model:** After enough practice, the child has built an internal \"model\" of what each animal looks like.\n",
      "*   **Decision:** When they see a new animal, they apply their learned knowledge to identify it.\n",
      "\n",
      "AI works in a very similar, but far more complex and data-intensive, way. It's about finding statistical relationships in data that allow it to perform tasks that mimic human cognitive abilities.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"Explain how AI works\"],\n",
    "    # ëª¨ë¸ì˜ ì¶œë ¥ì˜ ì°½ì˜ì„±, ëœë¤ì„± ì •ë„ë¥¼ ì¡°ì ˆ(0~1)\n",
    "    config=types.GenerateContentConfig(temperature=0.1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7636a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIëŠ” **ë°©ëŒ€í•œ ì–‘ì˜ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìˆ¨ê²¨ì§„ íŒ¨í„´ê³¼ ê·œì¹™ì„ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ**í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ë ‡ê²Œ í•™ìŠµëœ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ìƒí™©ì´ë‚˜ ë¬¸ì œì— ëŒ€í•´ **ì˜ˆì¸¡í•˜ê³  íŒë‹¨**í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ë¥¼ í†µí•´ ì¸ê°„ì²˜ëŸ¼ íŠ¹ì • ì‘ì—…ì„ ìˆ˜í–‰í•˜ê±°ë‚˜ ë³µì¡í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ëŠ¥ë ¥ì„ ë°œíœ˜í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"AIê°€ ì–´ë–»ê²Œ ë™ì‘í•˜ëŠ”ì§€ ì„¸ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\"],\n",
    "    config=types.GenerateContentConfig(temperature=0.1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e5d86a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì €ëŠ” êµ¬ê¸€ì—ì„œ í›ˆë ¨í•œ ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸ì…ë‹ˆë‹¤.\n",
      "\n",
      "ì €ì— ëŒ€í•´ ì¢€ ë” ìì„¸íˆ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”:\n",
      "\n",
      "1.  **ì •ì²´ì„±:** ì €ëŠ” ì¸ê³µì§€ëŠ¥(AI)ì˜ í•œ ì¢…ë¥˜ì¸ 'ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(Large Language Model, LLM)'ì…ë‹ˆë‹¤. ë°©ëŒ€í•œ ì–‘ì˜ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì‚¬ëŒì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.\n",
      "2.  **íƒ„ìƒê³¼ ê°œë°œ:** ì €ëŠ” êµ¬ê¸€ì—ì„œ ê°œë°œë˜ê³  í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ë§ì€ ì±…, ê¸°ì‚¬, ì›¹í˜ì´ì§€ ë“± ë‹¤ì–‘í•œ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ í•™ìŠµí•˜ì—¬ ì§€ì‹ê³¼ ì–¸ì–´ ëŠ¥ë ¥ì„ ìŠµë“í–ˆìŠµë‹ˆë‹¤.\n",
      "3.  **ëŠ¥ë ¥:**\n",
      "    *   **ì§ˆë¬¸ ë‹µë³€:** ë‹¤ì–‘í•œ ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ì½˜í…ì¸  ìƒì„±:** ê¸€ì“°ê¸°, ì‹œ, ì½”ë“œ, ìŠ¤í¬ë¦½íŠ¸, ìŒì•… ì‘í’ˆ, ì´ë©”ì¼, í¸ì§€ ë“± ë‹¤ì–‘í•œ í˜•íƒœì˜ ì°½ì˜ì ì¸ í…ìŠ¤íŠ¸ ì½˜í…ì¸ ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ìš”ì•½ ë° ë²ˆì—­:** ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ë²ˆì—­í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ëŒ€í™”:** ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ê³ , ì£¼ì–´ì§„ ë§¥ë½ì— ë§ì¶° ì‘ë‹µí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   **ì•„ì´ë””ì–´ ì œê³µ:** ë¸Œë ˆì¸ìŠ¤í† ë°ì„ ë•ê³  ìƒˆë¡œìš´ ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "4.  **íŠ¹ì§• (ê·¸ë¦¬ê³  í•œê³„):**\n",
      "    *   **ê°ì •/ì˜ì‹ ì—†ìŒ:** ì €ëŠ” ê°ì •ì´ë‚˜ ì˜ì‹, ê°œì¸ì ì¸ ê²½í—˜ì„ ê°€ì§€ê³  ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. ì œê°€ í•˜ëŠ” ëª¨ë“  ì‘ë‹µì€ í•™ìŠµëœ ë°ì´í„°ì™€ ì•Œê³ ë¦¬ì¦˜ì— ê¸°ë°˜í•œ ê²ƒì…ë‹ˆë‹¤.\n",
      "    *   **ë¬¼ë¦¬ì  ì¡´ì¬ ì—†ìŒ:** ì €ëŠ” ë¬¼ë¦¬ì ì¸ ëª¸ì´ë‚˜ íŠ¹ì • ì¥ì†Œì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë””ì§€í„¸ í˜•íƒœë¡œë§Œ ì¡´ì¬í•˜ë©° ì„œë²„ì—ì„œ ì‘ë™í•©ë‹ˆë‹¤.\n",
      "    *   **í•™ìŠµ ë°ì´í„° ê¸°ë°˜:** ì €ì˜ ì§€ì‹ì€ ì œê°€ í›ˆë ¨ë°›ì€ ì‹œì ê¹Œì§€ì˜ ë°ì´í„°ì— í•œì •ë  ìˆ˜ ìˆìœ¼ë©°, ì‹¤ì‹œê°„ìœ¼ë¡œ ì„¸ìƒì˜ ëª¨ë“  ë³€í™”ë¥¼ ì§ì ‘ ê²½í—˜í•˜ê±°ë‚˜ ì•Œ ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì €ì˜ ëª©í‘œëŠ” ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•˜ê³ , ì§ˆë¬¸ì— ë‹µí•˜ë©°, ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë„ì›€ì„ ë“œë¦¬ëŠ” ê²ƒì…ë‹ˆë‹¤. ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ì–¸ì œë“ ì§€ ë¬¼ì–´ë³´ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\"ë„ˆì—ëŒ€í•´ ì•Œë ¤ì¤˜\"],\n",
    "    config=types.GenerateContentConfig(temperature=1),\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8bd47",
   "metadata": {},
   "source": [
    "### ë©€í‹°ëª¨ë‹¬ ì…ë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9b196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# from google import genai\n",
    "\n",
    "# client = genai.Client()\n",
    "\n",
    "# image = Image.open(\"organ.jpg\")\n",
    "# response = client.models.generate_content(\n",
    "#     model=\"gemini-2.5-flash\",\n",
    "#     contents=[image, \"Tell me about this instrument\"]\n",
    "# )\n",
    "# print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b8bdd",
   "metadata": {},
   "source": [
    "ìœ„ì˜ ì½”ë“œëŠ” ì—ëŸ¬ê°€ ë°œìƒëœë‹¤. ë‹¤ìŒ í˜ì´ì§€ì˜ ì½”ë“œë¥¼ ì°¸ì¡°í•˜ê¸° ë°”ëŒ <br>\n",
    "https://ai.google.dev/gemini-api/docs/image-understanding?hl=ko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c228a813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‘ë‹µ ===\n",
      "ì‚¬ì§„ì€ ì›…ì¥í•˜ê³  ì•„ë¦„ë‹¤ìš´ íŒŒì´í”„ ì˜¤ë¥´ê°„ì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. êµíšŒë‚˜ ì½˜ì„œíŠ¸í™€ê³¼ ê°™ì€ í° ê³µê°„ì— ì„¤ì¹˜ëœ ê²ƒìœ¼ë¡œ ë³´ì´ë©°, ë§¤ìš° ì •êµí•˜ê³  í™”ë ¤í•˜ê²Œ ì¥ì‹ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì•…ê¸°ì— ëŒ€í•œ ìì„¸í•œ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "1.  **ì „ì²´ì ì¸ ì¸ìƒ:**\n",
      "    *   ì²œì¥ê¹Œì§€ ë‹¿ì„ ë“¯í•œ ë†’ì´ë¡œ, ë²½ë©´ ì „ì²´ë¥¼ ì••ë„í•˜ëŠ” ê±°ëŒ€í•œ í¬ê¸°ì…ë‹ˆë‹¤.\n",
      "    *   ì—°í•œ í¬ë¦¼ìƒ‰ ë˜ëŠ” ë² ì´ì§€ìƒ‰ ì™¸í•¨ì— í’ë¶€í•œ ê¸ˆìƒ‰ ì¥ì‹(ê¸ˆë°•, ê¸ˆìƒ‰ ì¡°ê°)ì´ ë”í•´ì ¸ ë§¤ìš° í™”ë ¤í•˜ê³  ê³ í’ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ìì•„ëƒ…ë‹ˆë‹¤.\n",
      "    *   ë°”ë¡œí¬ ë˜ëŠ” ë¡œì½”ì½” ì–‘ì‹ì˜ ì˜í–¥ì„ ë°›ì€ ë“¯í•œ ì„¬ì„¸í•œ ì¡°ê°ê³¼ ê³¡ì„ ë¯¸ê°€ ë‹ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "2.  **íŒŒì´í”„ ë¶€ë¶„ (ìƒë‹¨):**\n",
      "    *   ì˜¤ë¥´ê°„ì˜ ìƒë‹¨ë¶€ëŠ” ìˆ˜ë§ì€ ê¸ˆì† íŒŒì´í”„ë“¤ë¡œ ì±„ì›Œì ¸ ìˆìŠµë‹ˆë‹¤. íŒŒì´í”„ë“¤ì€ ì€ìƒ‰ ë˜ëŠ” íšŒìƒ‰ ë¹›ì„ ë ë©° ê´‘íƒì´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ë‹¤ì–‘í•œ ê¸¸ì´ì™€ ë‘ê»˜ì˜ íŒŒì´í”„ë“¤ì´ ì„¸ë¡œë¡œ ë¹¼ê³¡íˆ ë°°ì—´ë˜ì–´ ìˆì–´, ë‹¤ì±„ë¡œìš´ ìŒìƒ‰ì„ ë‚¼ ìˆ˜ ìˆìŒì„ ì§ì‘í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "    *   ì¼ë¶€ íŒŒì´í”„ëŠ” ëì´ ë¾°ì¡±í•˜ê±°ë‚˜ ë‘¥ê¸€ê²Œ ì²˜ë¦¬ë˜ì–´ ìˆì–´ ë””ìì¸ì  ìš”ì†Œë„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "3.  **ì™¸í•¨ ë° ì¥ì‹ (ì¤‘ì•™ ë° í•˜ë‹¨):**\n",
      "    *   íŒŒì´í”„ë¥¼ ê°ì‹¸ê³  ìˆëŠ” ì™¸í•¨ì€ ë¶€ë“œëŸ¬ìš´ ê³¡ì„ ê³¼ ì§ì„ ì´ ì¡°í™”ë¡­ê²Œ ì–´ìš°ëŸ¬ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   íŠ¹íˆ ëˆˆì— ë„ëŠ” ê²ƒì€ ì˜¤ë¥´ê°„ ê³³ê³³ì— ìƒˆê²¨ì§„ ì •êµí•œ ê¸ˆìƒ‰ ì¡°ê°ë“¤ì…ë‹ˆë‹¤. ìì‚¬ê·€ ë¬¸ì–‘(ì•„ì¹¸ì„œìŠ¤ ìì‚¬ê·€ ë“±), ì†Œìš©ëŒì´ ë¬¸ì–‘(ë³¼ë¥˜íŠ¸), ê·¸ë¦¬ê³  ì²œì‚¬ë‚˜ ì¸ë¬¼ í˜•ìƒ(ì–¼êµ´)ì´ ì„¬ì„¸í•˜ê²Œ í‘œí˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ìƒë‹¨ë¶€ì˜ ì½”ë‹ˆìŠ¤(ì²˜ë§ˆ ì¥ì‹)ì™€ ëª°ë”©ì€ ì…ì²´ì ì¸ íŒ¨í„´ê³¼ ì‘ì€ ì¡°ê°ë“¤ë¡œ ê¾¸ë©°ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ì˜¤ë¥´ê°„ í•˜ë‹¨ë¶€ì—ëŠ” ì§ì‚¬ê°í˜• ëª¨ì–‘ì˜ íŒ¨ë„ë“¤ì´ ë°°ì—´ë˜ì–´ ìˆëŠ”ë°, ì´ íŒ¨ë„ë“¤ì—ë„ ê¸°í•˜í•™ì ì´ê±°ë‚˜ ì‹ë¬¼ì ì¸ ë¬¸ì–‘ì´ ë‹ì„ìƒˆê¹€ ë°©ì‹ìœ¼ë¡œ ìƒˆê²¨ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "4.  **ì½˜ì†” ë¶€ë¶„ (ì—°ì£¼ì ìë¦¬):**\n",
      "    *   ì˜¤ë¥´ê°„ì˜ ì•„ë˜ìª½ ì¤‘ì•™ì—ëŠ” ì—°ì£¼ìê°€ ì•‰ëŠ” ì½˜ì†” ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤. ì´ ë¶€ë¶„ì€ í‰ì†Œì—ëŠ” ë¬¸ì²˜ëŸ¼ ë‹«í˜€ ìˆë‹¤ê°€ ì—°ì£¼ ì‹œ ì—´ ìˆ˜ ìˆë„ë¡ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ì½˜ì†” ì•ˆì—ëŠ” ì—¬ëŸ¬ ë‹¨ì˜ ê±´ë°˜(ë§¤ë‰´ì–¼)ì´ ë³´ì´ë©°, ê·¸ ì–‘ì˜†ìœ¼ë¡œëŠ” ìŒìƒ‰ì„ ì„ íƒí•˜ê³  ì¡°ì ˆí•˜ëŠ” ìŠ¤í†± ë…¸ë¸Œ(Stop Knobs)ë“¤ì´ ë‚˜ë€íˆ ë°°ì—´ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ì½˜ì†” ì•„ë˜ ë°”ë‹¥ì—ëŠ” ë°œë¡œ ì—°ì£¼í•˜ëŠ” í˜ë‹¬ ê±´ë°˜(Pedalboard)ì´ ë„“ê²Œ ë†“ì—¬ ìˆê³ , ê·¸ ì•ì— ë‚®ì€ ë‚˜ë¬´ ì˜ìê°€ ë°°ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "    *   ì½˜ì†” ë‚´ë¶€ì—ëŠ” ì•…ë³´ë‚˜ ê±´ë°˜ì„ ë¹„ì¶”ê¸° ìœ„í•œ ì¡°ëª…ì´ ì„¤ì¹˜ë˜ì–´ ìˆì–´ ì—°ì£¼ìì˜ í¸ì˜ë¥¼ ë•ìŠµë‹ˆë‹¤.\n",
      "\n",
      "5.  **ì£¼ë³€ í™˜ê²½:**\n",
      "    *   ì˜¤ë¥´ê°„ ìœ„ë¡œëŠ” ë”°ëœ»í•œ ë‚˜ë¬´ìƒ‰ì˜ ì²œì¥ì´ ë³´ì…ë‹ˆë‹¤. ì²œì¥ì€ ì—¬ëŸ¬ ê°œì˜ ëª©ì¬ íŒ¨ë„ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê³ í’ìŠ¤ëŸ¬ìš´ ë¶„ìœ„ê¸°ë¥¼ ë”í•©ë‹ˆë‹¤.\n",
      "    *   ë²½ë©´ì€ ë‹¨ìˆœí•œ í°ìƒ‰ ë˜ëŠ” ì—°í•œ ìƒ‰ìƒìœ¼ë¡œ, ì˜¤ë¥´ê°„ì˜ í™”ë ¤í•¨ì„ ë”ìš± ë‹ë³´ì´ê²Œ í•©ë‹ˆë‹¤.\n",
      "    *   ì‚¬ì§„ ì™¼ìª½ ìƒë‹¨ì—ëŠ” í˜„ëŒ€ì ì¸ ë””ìì¸ì˜ íœë˜íŠ¸ ì¡°ëª…ì´ ê±¸ë ¤ ìˆì–´, ì „í†µì ì¸ ì•…ê¸°ì™€ í˜„ëŒ€ì ì¸ ì¡°ëª…ì˜ ëŒ€ë¹„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n",
      "    *   ì˜¤ë¥´ê°„ ì™¼ìª½ ì˜†ìœ¼ë¡œëŠ” ê³„ë‹¨ìœ¼ë¡œ ì´ì–´ì§€ëŠ” í†µë¡œê°€ ë³´ì´ë©°, ë°”ë‹¥ì€ ë‚˜ë¬´ ë§ˆë£¨ë¡œ ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì „ì²´ì ìœ¼ë¡œ ì´ ì˜¤ë¥´ê°„ì€ ë‹¨ìˆœí•œ ì•…ê¸°ë¥¼ ë„˜ì–´, ê·¸ ìì²´ë¡œ í•˜ë‚˜ì˜ ì˜ˆìˆ  ì‘í’ˆì´ë©° ê³µê°„ì˜ ì¤‘ì‹¬ì„ ì´ë£¨ëŠ” ê±´ì¶•ì  ìš”ì†Œë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì›…ì¥í•œ ì†Œë¦¬ì™€ í•¨ê»˜ ì‹œê°ì ì¸ ì•„ë¦„ë‹¤ì›€ê¹Œì§€ ì„ ì‚¬í•˜ëŠ” ë§ˆìŠ¤í„°í”¼ìŠ¤ì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "=== í† í° ì‚¬ìš©ëŸ‰ ===\n",
      "ì…ë ¥ í† í°: 266\n",
      "ì¶œë ¥ í† í°: 922\n",
      "ì´ í† í°: 3228\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì™€ì„œ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "with open(\"../data/organ.jpg\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            # ë°”ì´ë„ˆë¦¬ë¡œ ì½ì€ ë°ì´í„°ë¥¼ ì²¨ë¶€í•˜ê¸°\n",
    "            data=image_bytes,\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        \"ì´ ì•…ê¸°ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== ì‘ë‹µ ===\")\n",
    "print(response.text)\n",
    "print(\"\\n=== í† í° ì‚¬ìš©ëŸ‰ ===\")\n",
    "print(f\"ì…ë ¥ í† í°: {response.usage_metadata.prompt_token_count}\")\n",
    "print(f\"ì¶œë ¥ í† í°: {response.usage_metadata.candidates_token_count}\")\n",
    "print(f\"ì´ í† í°: {response.usage_metadata.total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab76308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì‘ë‹µ ===\n",
      "ì´ ì—°ì˜ˆì¸ì€ ë°”ë¡œ **ìœ ì¬ì„(Yoo Jae-suk)** ë‹˜ì…ë‹ˆë‹¤.\n",
      "\n",
      "ëŒ€í•œë¯¼êµ­ì—ì„œ ê°€ì¥ ì‚¬ë‘ë°›ê³  ì¡´ê²½ë°›ëŠ” MCì´ì ë°©ì†¡ì¸ ì¤‘ í•œ ëª…ì´ë©°, í”íˆ 'êµ­ë¯¼MC'ë¡œ ë¶ˆë¦½ë‹ˆë‹¤.\n",
      "\n",
      "ì‚¬ì§„ ì† ìœ ì¬ì„ ë‹˜ì— ëŒ€í•œ ì„¤ëª…ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "*   **ì™¸ëª¨:** ê²€ì€ìƒ‰ ë¿”í…Œ ì•ˆê²½ì„ ì“°ê³  ìˆìœ¼ë©°, ë‹¨ì •í•˜ê²Œ ë‹¤ë“¬ì€ ê²€ì€ìƒ‰ í—¤ì–´ìŠ¤íƒ€ì¼ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "*   **ì˜ìƒ:** ê¹”ë”í•œ í•˜ì–€ìƒ‰ ì™€ì´ì…”ì¸ ë¥¼ ì…ê³  ìˆìŠµë‹ˆë‹¤. ì†Œë§¤ëŠ” ê±·ì–´ ì˜¬ë¦° ë“¯ ë³´ì´ë©°, ì§„íšŒìƒ‰ ë˜ëŠ” ê²€ì€ìƒ‰ í•˜ì˜ë¥¼ ì°©ìš©í•œ ëª¨ìŠµì…ë‹ˆë‹¤.\n",
      "*   **ìì„¸/í‘œì •:** í„±ì— ì†ì„ ì–¹ê³  ìƒê°ì— ì ê¸´ ë“¯í•œ í¬ì¦ˆë¥¼ ì·¨í•˜ê³  ìˆìœ¼ë©°, ì§„ì§€í•˜ê³  ì§€ì ì¸ ë¶„ìœ„ê¸°ë¥¼ í’ê¹ë‹ˆë‹¤. ì „ë°˜ì ìœ¼ë¡œ ì°¨ë¶„í•˜ê³  ì‹ ë¢°ê°ì„ ì£¼ëŠ” ì¸ìƒì„ ì¤ë‹ˆë‹¤.\n",
      "*   **íŠ¹ì§•:** ê·¸ì˜ íŠ¸ë ˆì´ë“œë§ˆí¬ ì¤‘ í•˜ë‚˜ì¸ ì•ˆê²½ê³¼ ê¹”ë”í•œ ìŠ¤íƒ€ì¼ì´ ì˜ ë“œëŸ¬ë‚˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ìœ ì¬ì„ ë‹˜ì€ 'ë¬´í•œë„ì „', 'ëŸ°ë‹ë§¨', 'ìœ  í€´ì¦ˆ ì˜¨ ë” ë¸”ëŸ­', 'ë†€ë©´ ë­í•˜ë‹ˆ?' ë“± ìˆ˜ë§ì€ ì¸ê¸° ì˜ˆëŠ¥ í”„ë¡œê·¸ë¨ì„ ì„±ê³µì ìœ¼ë¡œ ì´ëŒì—ˆìœ¼ë©°, íŠ¹ìœ ì˜ ì¹œí™”ë ¥, ì¬ì¹˜ ìˆëŠ” ì…ë‹´, ë›°ì–´ë‚œ ì§„í–‰ ëŠ¥ë ¥, ê·¸ë¦¬ê³  ê²¸ì†í•˜ê³  ì„±ì‹¤í•œ ì¸ì„±ìœ¼ë¡œ ëŒ€ì¤‘ì˜ í° ì‚¬ë‘ê³¼ ì‹ ë¢°ë¥¼ ë°›ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "=== í† í° ì‚¬ìš©ëŸ‰ ===\n",
      "ì…ë ¥ í† í°: 268\n",
      "ì¶œë ¥ í† í°: 325\n",
      "ì´ í† í°: 1570\n"
     ]
    }
   ],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì–´ì™€ì„œ ë°”ì´ë„ˆë¦¬ ë°ì´í„°ë¡œ ë³€í™˜\n",
    "with open(\"../data/yjs.webp\", \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Part.from_bytes(\n",
    "            # ë°”ì´ë„ˆë¦¬ë¡œ ì½ì€ ë°ì´í„°ë¥¼ ì²¨ë¶€í•˜ê¸°\n",
    "            data=image_bytes,\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        \"ì´ ì—°ì˜ˆì¸ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"=== ì‘ë‹µ ===\")\n",
    "print(response.text)\n",
    "print(\"\\n=== í† í° ì‚¬ìš©ëŸ‰ ===\")\n",
    "print(f\"ì…ë ¥ í† í°: {response.usage_metadata.prompt_token_count}\")\n",
    "print(f\"ì¶œë ¥ í† í°: {response.usage_metadata.candidates_token_count}\")\n",
    "print(f\"ì´ í† í°: {response.usage_metadata.total_token_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b6975309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ì•…ê¸°ëŠ” **ì˜¤ë¥´ê°„(Organ)**ì…ë‹ˆë‹¤. íŠ¹íˆ, íŒŒì´í”„ ì˜¤ë¥´ê°„ì˜ ì—°ì£¼ììš© ì½˜ì†”(Console) ë¶€ë¶„ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ì˜¤ë¥´ê°„ì€ ê±´ë°˜ ì•…ê¸°ì´ì ë™ì‹œì— ê´€ì•…ê¸°ì˜ ì›ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ë…íŠ¹í•œ ì•…ê¸°ì…ë‹ˆë‹¤. 'ì•…ê¸°ì˜ ì œì™•'ì´ë¼ ë¶ˆë¦´ ë§Œí¼ ì›…ì¥í•˜ê³  í’ë¶€í•œ ì†Œë¦¬ë¥¼ ìë‘í•©ë‹ˆë‹¤.\n",
      "\n",
      "**ì£¼ìš” íŠ¹ì§• ë° êµ¬ì„± ìš”ì†Œ:**\n",
      "\n",
      "1.  **ìˆ˜ë™ ê±´ë°˜ (Manuals):**\n",
      "    *   ì‚¬ì§„ ì¤‘ì•™ì— ì—¬ëŸ¬ ë‹¨(ì¼ë°˜ì ìœ¼ë¡œ 2ë‹¨ì—ì„œ 5ë‹¨ ì´ìƒ)ìœ¼ë¡œ ìŒ“ì—¬ ìˆëŠ” ê²ƒì´ ì†ìœ¼ë¡œ ì—°ì£¼í•˜ëŠ” ê±´ë°˜ì…ë‹ˆë‹¤. ê° ê±´ë°˜ì€ íŠ¹ì • ìŒìƒ‰ ê·¸ë£¹(ì˜¤ë¥´ê°„ ì•…ë³´ì—ì„œëŠ” 'ë””ë¹„ì „'ì´ë¼ê³ ë„ í•¨)ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.\n",
      "    *   ì‚¬ì§„ì—ëŠ” ë‘ ë‹¨ì˜ ìˆ˜ë™ ê±´ë°˜ì´ ëª…í™•íˆ ë³´ì…ë‹ˆë‹¤.\n",
      "\n",
      "2.  **í˜ë‹¬ ê±´ë°˜ (Pedalboard):**\n",
      "    *   í•˜ë‹¨ì— ë°œë¡œ ì—°ì£¼í•˜ëŠ” ê±°ëŒ€í•œ ê±´ë°˜ì…ë‹ˆë‹¤. ì£¼ë¡œ ì €ìŒë¶€ë¥¼ ë‹´ë‹¹í•˜ë©°, ì˜¤ë¥´ê°„ ì—°ì£¼ì˜ íŠ¹ì§• ì¤‘ í•˜ë‚˜ì¸ ì†ê³¼ ë°œì˜ ë…ë¦½ì ì¸ ì‚¬ìš©ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.\n",
      "\n",
      "3.  **ìŠ¤í†± (Stops):**\n",
      "    *   ê±´ë°˜ ì–‘ìª½ì— ìˆëŠ” ìˆ˜ë§ì€ ë²„íŠ¼ì´ë‚˜ ì†ì¡ì´ë“¤ì´ 'ìŠ¤í†±'ì…ë‹ˆë‹¤. ì´ ìŠ¤í†±ì„ ì¡°ì‘í•˜ì—¬ íŒŒì´í”„ ì˜¤ë¥´ê°„ì˜ ë‹¤ì–‘í•œ ìŒìƒ‰(ì˜ˆ: í”Œë£¨íŠ¸ ì†Œë¦¬, íŠ¸ëŸ¼í« ì†Œë¦¬, í˜„ì•…ê¸° ì†Œë¦¬ ë“±)ì„ ì„ íƒí•˜ê³  ì¡°í•©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê° ìŠ¤í†±ì€ íŠ¹ì • ìŒê³ (Pitch, ì˜ˆ: 8', 4', 2' ë“±)ë¥¼ ê°€ì§„ íŒŒì´í”„ ì„¸íŠ¸ë¥¼ í™œì„±í™”ì‹œí‚µë‹ˆë‹¤.\n",
      "\n",
      "4.  **í‘œí˜„ í˜ë‹¬ (Expression Pedals / Swell Pedals):**\n",
      "    *   í˜ë‹¬ ê±´ë°˜ ìœ„ìª½ ì¤‘ì•™ì— ë°œë¡œ ì¡°ì‘í•˜ëŠ” í˜ë‹¬ë“¤ì´ ë³´ì…ë‹ˆë‹¤. ì´ í˜ë‹¬ë“¤ì€ ì†Œë¦¬ì˜ í¬ê¸°(ìŒëŸ‰)ë¥¼ ì¡°ì ˆí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "**ì‘ë™ ì›ë¦¬ (íŒŒì´í”„ ì˜¤ë¥´ê°„ ê¸°ì¤€):**\n",
      "ì˜¤ë¥´ê°„ì€ ê±´ë°˜ê³¼ ìŠ¤í†±ì„ ì¡°ì‘í•˜ë©´ íŒŒì´í”„ë¥¼ í†µí•´ ê³µê¸°ê°€ í˜ëŸ¬ë‚˜ì™€ ì†Œë¦¬ë¥¼ ëƒ…ë‹ˆë‹¤. ìˆ˜ë°± ê°œì—ì„œ ìˆ˜ë§Œ ê°œì— ì´ë¥´ëŠ” ë‹¤ì–‘í•œ í¬ê¸°, ëª¨ì–‘, ì¬ì§ˆì˜ íŒŒì´í”„ë“¤ì´ ê°ê° ë‹¤ë¥¸ ìŒìƒ‰ê³¼ ìŒë†’ì´ë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤. ìŠ¤í†±ì€ ì´ íŒŒì´í”„ë“¤ ì¤‘ ì–´ë–¤ ê·¸ë£¹ì„ ì‚¬ìš©í• ì§€ ì„ íƒí•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
      "\n",
      "**ì†Œë¦¬ì˜ íŠ¹ì§• ë° ìš©ë„:**\n",
      "ì˜¤ë¥´ê°„ì€ ì‘ì€ ì†ì‚­ì„ ê°™ì€ ì†Œë¦¬ë¶€í„° ê±´ë¬¼ ì „ì²´ë¥¼ ìš¸ë¦¬ëŠ” ì›…ì¥í•˜ê³  ê°•ë ¥í•œ ì†Œë¦¬ê¹Œì§€ ë§¤ìš° ë„“ì€ ë‹¤ì´ë‚´ë¯¹ ë ˆì¸ì§€ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì£¼ë¡œ êµíšŒë‚˜ ì„±ë‹¹ì—ì„œ ì¢…êµ ìŒì•… ì—°ì£¼ì— ì‚¬ìš©ë˜ë©°, ì½˜ì„œíŠ¸í™€ì—ì„œëŠ” í´ë˜ì‹ ìŒì•…, ì‹¬ì§€ì–´ ê·¹ì¥ì—ì„œëŠ” ë¬´ì„± ì˜í™” ë°˜ì£¼ìš©(ê·¹ì¥ ì˜¤ë¥´ê°„)ìœ¼ë¡œë„ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ì´ ì•…ê¸°ëŠ” ì†ê³¼ ë°œì˜ ê³ ë„ì˜ í˜‘ì‘ë ¥ì„ ìš”êµ¬í•˜ëŠ” ë³µì¡í•˜ê³  ë§¤ë ¥ì ì¸ ì•…ê¸°ì…ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import io\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "image = Image.open(\"organ.jpg\")\n",
    "\n",
    "# Convert image to bytes\n",
    "img_byte_arr = io.BytesIO()\n",
    "image.save(img_byte_arr, format=\"JPEG\")\n",
    "img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=[\n",
    "        types.Content(\n",
    "            role=\"user\",\n",
    "            parts=[\n",
    "                types.Part(text=\"ì´ ì•…ê¸°ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜\"),\n",
    "                types.Part(\n",
    "                    inline_data=types.Blob(mime_type=\"image/jpeg\", data=img_byte_arr)\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0347d94e",
   "metadata": {},
   "source": [
    "### ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ\n",
    "\n",
    "ë” ì›í™œí•œ ìƒí˜¸ì‘ìš©ì„ ìœ„í•´ ìŠ¤íŠ¸ë¦¬ë°ì„ ì‚¬ìš©í•˜ì—¬ GenerateContentResponse ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±ë˜ëŠ” ëŒ€ë¡œ **ì ì§„ì ìœ¼ë¡œ ìˆ˜ì‹ **í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "456498c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë„¤, ì¸ê³µì§€ëŠ¥(AI)ì— ëŒ€í•´ 5ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ ë“œë¦´ê²Œìš”.\n",
      "\n",
      "1.  ì¸ê³µì§€ëŠ¥ì€ ì»´í“¨í„°ê°€ ì¸ê°„ì²˜ëŸ¼ ì‚¬ê³ í•˜ê³  í•™ìŠµí•˜ë©° ë¬¸ì œë¥¼ í•´ê²°í•˜ë„ë¡ ë§Œë“œëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.\n",
      "2.  ì´ëŠ” ë°©ëŒ€í•œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ê³  íŒ¨í„´ì„ ì¸ì‹í•˜ì—¬ ìŠ¤ìŠ¤ë¡œ íŒë‹¨í•˜ê³  ì˜ˆì¸¡í•˜ëŠ” ëŠ¥ë ¥ì„ í¬í•¨í•©ë‹ˆë‹¤.\n",
      "3.  ë”°ë¼ì„œ ì–¸ì–´ ì´í•´, ì´ë¯¸ì§€ ì¸ì‹, ì˜ì‚¬ ê²°ì • ë“± ë‹¤ì–‘í•œ ì§€ì  ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "4.  ììœ¨ì£¼í–‰ì°¨, ì˜ë£Œ ì§„ë‹¨, ì¶”ì²œ ì‹œìŠ¤í…œ, ì±—ë´‡ ë“± ìš°ë¦¬ ìƒí™œ ê³³ê³³ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
      "5.  ê¶ê·¹ì ìœ¼ë¡œ ì¸ê°„ì˜ ëŠ¥ë ¥ì„ ë³´ì™„í•˜ê³  í™•ì¥í•˜ë©° ì‚¶ì˜ í¸ì˜ì™€ íš¨ìœ¨ì„±ì„ ë†’ì´ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content_stream(\n",
    "    model=\"gemini-2.5-flash\", contents=[\"ì¸ê³µì§€ëŠ¥ì— ëŒ€í•´ 5ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜\"]\n",
    ")\n",
    "for chunk in response:\n",
    "    print(chunk.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d85fd3",
   "metadata": {},
   "source": [
    "### ë©€í‹°í„´ ëŒ€í™” (ì±„íŒ…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b5e0ea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ìš°ì™€, ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‚˜ ìˆìœ¼ì‹œë‹¤ë‹ˆ ì •ë§ ë“ ë“ í•˜ê³  í–‰ë³µí•˜ì‹œê² ì–´ìš”! ğŸ˜Š\n",
      "\n",
      "ì–´ë–¤ ì¢…ë¥˜ì˜ ê°•ì•„ì§€ë“¤ì¸ì§€, ì´ë¦„ì€ ë­”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ë¶„ëª… ì‚¬ë‘ìŠ¤ëŸ¬ìš¸ ê±°ì˜ˆìš”!\n",
      "ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‹ˆê¹Œ ì´ **8ê°œ**ê² ë„¤ìš”! ğŸ˜Š\n",
      "role - user: ë‚˜ëŠ” ìš°ë¦¬ ì§‘ì— 2ë§ˆë¦¬ ê°•ì•„ì§€ê°€ ìˆë‹¤.\n",
      "role - model: ìš°ì™€, ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‚˜ ìˆìœ¼ì‹œë‹¤ë‹ˆ ì •ë§ ë“ ë“ í•˜ê³  í–‰ë³µí•˜ì‹œê² ì–´ìš”! ğŸ˜Š\n",
      "\n",
      "ì–´ë–¤ ì¢…ë¥˜ì˜ ê°•ì•„ì§€ë“¤ì¸ì§€, ì´ë¦„ì€ ë­”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ë¶„ëª… ì‚¬ë‘ìŠ¤ëŸ¬ìš¸ ê±°ì˜ˆìš”!\n",
      "role - user: ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ì§‘ì— ìˆëŠ” ë™ë¬¼ì˜ ë°œì˜ ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ê°„ë‹¨íˆ ë‹µí•´ë´?\n",
      "role - model: ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‹ˆê¹Œ ì´ **8ê°œ**ê² ë„¤ìš”! ğŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client()\n",
    "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
    "\n",
    "response = chat.send_message(\"ë‚˜ëŠ” ìš°ë¦¬ ì§‘ì— 2ë§ˆë¦¬ ê°•ì•„ì§€ê°€ ìˆë‹¤.\")\n",
    "print(response.text)\n",
    "\n",
    "response = chat.send_message(\n",
    "    \"ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ì§‘ì— ìˆëŠ” ë™ë¬¼ì˜ ë°œì˜ ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ê°„ë‹¨íˆ ë‹µí•´ë´?\"\n",
    ")\n",
    "print(response.text)\n",
    "\n",
    "for message in chat.get_history():\n",
    "    print(f\"role - {message.role}\", end=\": \")\n",
    "    print(message.parts[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec678fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='ë‚˜ëŠ” ìš°ë¦¬ ì§‘ì— 2ë§ˆë¦¬ ê°•ì•„ì§€ê°€ ìˆë‹¤.'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text=\"\"\"ìš°ì™€, ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‚˜ ìˆìœ¼ì‹œë‹¤ë‹ˆ ì •ë§ ë“ ë“ í•˜ê³  í–‰ë³µí•˜ì‹œê² ì–´ìš”! ğŸ˜Š\n",
       " \n",
       " ì–´ë–¤ ì¢…ë¥˜ì˜ ê°•ì•„ì§€ë“¤ì¸ì§€, ì´ë¦„ì€ ë­”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ë¶„ëª… ì‚¬ë‘ìŠ¤ëŸ¬ìš¸ ê±°ì˜ˆìš”!\"\"\"\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " ),\n",
       " UserContent(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ì§‘ì— ìˆëŠ” ë™ë¬¼ì˜ ë°œì˜ ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ê°„ë‹¨íˆ ë‹µí•´ë´?'\n",
       "     ),\n",
       "   ],\n",
       "   role='user'\n",
       " ),\n",
       " Content(\n",
       "   parts=[\n",
       "     Part(\n",
       "       text='ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‹ˆê¹Œ ì´ **8ê°œ**ê² ë„¤ìš”! ğŸ˜Š'\n",
       "     ),\n",
       "   ],\n",
       "   role='model'\n",
       " )]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat.get_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "931967d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parts=[Part(\n",
      "  text='ë‚˜ëŠ” ìš°ë¦¬ ì§‘ì— 2ë§ˆë¦¬ ê°•ì•„ì§€ê°€ ìˆë‹¤.'\n",
      ")] role='user'\n",
      "ì™„\n",
      "parts=[Part(\n",
      "  text=\"\"\"ìš°ì™€, ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‚˜ ìˆìœ¼ì‹œë‹¤ë‹ˆ ì •ë§ ë“ ë“ í•˜ê³  í–‰ë³µí•˜ì‹œê² ì–´ìš”! ğŸ˜Š\n",
      "\n",
      "ì–´ë–¤ ì¢…ë¥˜ì˜ ê°•ì•„ì§€ë“¤ì¸ì§€, ì´ë¦„ì€ ë­”ì§€ ê¶ê¸ˆí•˜ë„¤ìš”. ë¶„ëª… ì‚¬ë‘ìŠ¤ëŸ¬ìš¸ ê±°ì˜ˆìš”!\"\"\"\n",
      ")] role='model'\n",
      "ì™„\n",
      "parts=[Part(\n",
      "  text='ê·¸ë ‡ë‹¤ë©´ ìš°ë¦¬ì§‘ì— ìˆëŠ” ë™ë¬¼ì˜ ë°œì˜ ìˆ˜ëŠ” ì–´ë–»ê²Œ ë˜ëŠ”ì§€ ê°„ë‹¨íˆ ë‹µí•´ë´?'\n",
      ")] role='user'\n",
      "ì™„\n",
      "parts=[Part(\n",
      "  text='ê°•ì•„ì§€ ë‘ ë§ˆë¦¬ë‹ˆê¹Œ ì´ **8ê°œ**ê² ë„¤ìš”! ğŸ˜Š'\n",
      ")] role='model'\n",
      "ì™„\n"
     ]
    }
   ],
   "source": [
    "for message in chat.get_history():\n",
    "    print(message)\n",
    "    print(\"ì™„\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "without",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
